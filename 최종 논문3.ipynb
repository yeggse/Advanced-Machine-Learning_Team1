{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnypuKdcJfVJ",
        "outputId": "46aeed11-9ca8-43cb-cb58-1af26706a34b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Churn_Pattern_Group  Accuracy  Precision    Recall  Specificity  F1-Score  \\\n",
            "0                    0  0.913216   1.000000  0.043689     1.000000  0.083721   \n",
            "1                    1  0.881664   0.867159  0.810345     0.924843  0.837790   \n",
            "\n",
            "   ROC AUC Score  \n",
            "0       0.521845  \n",
            "1       0.867594  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "# 데이터셋 불러오기\n",
        "file_path = '/content/BankChurners.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# 데이터 전처리\n",
        "\n",
        "# Naive Bayes 관련 열 제거\n",
        "df.drop(['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1',\n",
        "         'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2'], axis=1, inplace=True)\n",
        "\n",
        "# 불필요한 열 제거 ('CLIENTNUM')\n",
        "df.drop(columns=['CLIENTNUM'], inplace=True)\n",
        "\n",
        "# 범주형 변수를 수치형으로 매핑\n",
        "df['Attrition_Flag'] = df['Attrition_Flag'].map({'Existing Customer': 0, 'Attrited Customer': 1})\n",
        "df['Gender'] = df['Gender'].map({'M': 1, 'F': 0})\n",
        "df['Education_Level'] = df['Education_Level'].map({\n",
        "    'Unknown': 0, 'Uneducated': 1, 'High School': 2, 'College': 3,\n",
        "    'Graduate': 4, 'Post-Graduate': 5, 'Doctorate': 6\n",
        "})\n",
        "df['Marital_Status'] = df['Marital_Status'].map({'Unknown': 0, 'Single': 1, 'Married': 2, 'Divorced': 3})\n",
        "df['Income_Category'] = df['Income_Category'].map({\n",
        "    'Unknown': 0, 'Less than $40K': 1, '$40K - $60K': 2, '$60K - $80K': 3,\n",
        "    '$80K - $120K': 4, '$120K +': 5\n",
        "})\n",
        "df['Card_Category'] = df['Card_Category'].map({'Blue': 1, 'Silver': 2, 'Gold': 3, 'Platinum': 4})\n",
        "\n",
        "# 목표 변수와 특성 변수 분리\n",
        "target_column = 'Attrition_Flag'\n",
        "X = df.drop(target_column, axis=1)\n",
        "y = df[target_column]\n",
        "\n",
        "# 특징 표준화\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# 양적 로열티 세분화\n",
        "quantitative_features = ['Total_Relationship_Count', 'Months_on_book', 'Total_Revolving_Bal']\n",
        "X_quant = X[quantitative_features]\n",
        "kmeans_quant = KMeans(n_clusters=4, random_state=42)\n",
        "X['Quant_Loyalty_Segment'] = kmeans_quant.fit_predict(X_quant)\n",
        "\n",
        "# 질적 로열티 세분화\n",
        "qualitative_features = ['Contacts_Count_12_mon', 'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1']\n",
        "X_qual = X[qualitative_features]\n",
        "kmeans_qual = KMeans(n_clusters=3, random_state=42)\n",
        "X['Qual_Loyalty_Segment'] = kmeans_qual.fit_predict(X_qual)\n",
        "\n",
        "# 이차원 세분화\n",
        "X['Loyalty_Segment'] = X['Quant_Loyalty_Segment'].astype(str) + '_' + X['Qual_Loyalty_Segment'].astype(str)\n",
        "\n",
        "# 이탈 패턴 그룹화\n",
        "segment_churn_rates = X.join(y).groupby('Loyalty_Segment')[target_column].mean()\n",
        "segment_churn_groups = segment_churn_rates.apply(lambda x: 0 if x < 0.2 else (1 if x < 0.5 else 2))\n",
        "X['Churn_Pattern_Group'] = X['Loyalty_Segment'].map(segment_churn_groups)\n",
        "\n",
        "# 데이터 학습 및 테스트 분할 (불균형 처리를 생략하여 진행)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# 각 이탈 패턴 그룹에 대해 모델 학습 및 평가 (Specificity 추가)\n",
        "results = []\n",
        "for group in X['Churn_Pattern_Group'].unique():\n",
        "    # 현재 그룹에 대한 데이터 필터링\n",
        "    X_train_group = X_train[X_train['Churn_Pattern_Group'] == group].drop(columns=['Quant_Loyalty_Segment', 'Qual_Loyalty_Segment', 'Loyalty_Segment', 'Churn_Pattern_Group'])\n",
        "    y_train_group = y_train[X_train.index.isin(X_train_group.index)]\n",
        "    X_test_group = X_test[X_test['Churn_Pattern_Group'] == group].drop(columns=['Quant_Loyalty_Segment', 'Qual_Loyalty_Segment', 'Loyalty_Segment', 'Churn_Pattern_Group'])\n",
        "    y_test_group = y_test[X_test.index.isin(X_test_group.index)]\n",
        "\n",
        "    # 그룹별 모델 선택 (랜덤 포레스트, Gradient Boosting, 로지스틱 회귀)\n",
        "    if group == 0:\n",
        "        model = RandomForestClassifier(random_state=42, max_depth=3, n_estimators=50, min_samples_split=5)\n",
        "    elif group == 1:\n",
        "        model = GradientBoostingClassifier(random_state=42, n_estimators=50, learning_rate=0.05, max_depth=2)\n",
        "    else:\n",
        "        model = LogisticRegression(random_state=42, max_iter=3000, solver='liblinear', penalty='l2', tol=1e-3)\n",
        "\n",
        "    # 모델 학습\n",
        "    model.fit(X_train_group, y_train_group)\n",
        "\n",
        "    # 예측 수행\n",
        "    y_pred = model.predict(X_test_group)\n",
        "\n",
        "    # 모델 평가\n",
        "    accuracy = accuracy_score(y_test_group, y_pred)\n",
        "    precision = precision_score(y_test_group, y_pred)\n",
        "    recall = recall_score(y_test_group, y_pred)\n",
        "\n",
        "    # Specificity 계산\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test_group, y_pred).ravel()\n",
        "    specificity = tn / (tn + fp)\n",
        "\n",
        "    f1 = f1_score(y_test_group, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test_group, y_pred)\n",
        "\n",
        "    # 결과 저장\n",
        "    results.append({\n",
        "        'Churn_Pattern_Group': group,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'Specificity': specificity,\n",
        "        'F1-Score': f1,\n",
        "        'ROC AUC Score': roc_auc\n",
        "    })\n",
        "\n",
        "# 결과 출력 (데이터프레임 출력)\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CyMArhxFKAY6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}